{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:31:20.302768Z",
     "start_time": "2023-05-16T10:30:53.974739Z"
    },
    "collapsed": true,
    "id": "o3XLG2RjlCBE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, prange, njit, config\n",
    "\n",
    "sys.setrecursionlimit(20000)\n",
    "\n",
    "from numba.typed import Dict, List\n",
    "\n",
    "from scripts import test_mutation, calculate_all_fitnesses, calculate_fitness, genotype_hash,deep_copy_genotype, mutate_genotype_inplace, assert_equality_of_hashes\n",
    "from scripts import random_int, NODE_TYPE, GENOTYPE_TYPE, best_n_items, create_full_tree_from_genome, seed\n",
    "from scripts import create_n_genotypes, crossover_numba, selection_tournament\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "#load_and_print_csvs_from_folders()\n",
    "#test_n_creation()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* Parametrizar o tamanho da seleção com lexicase\n",
    "* Criar função de rodar experimentos para arquivo\n",
    "* Extrair as funções do arquivo scripts.py\n",
    "* Falar da implentação de lexicase\n",
    "* Falar do cache\n",
    "* Documentar os arquivos e funções\n",
    "* Executar testes nesse notebook, extraindo a função main aqui pra dentro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Define the name of your cache file\n",
    "cache_file = \"cache.csv\"\n",
    "\n",
    "cache = None\n",
    "# Create an empty DataFrame if cache file doesn't exist\n",
    "if not os.path.isfile(cache_file):\n",
    "    cache = pd.DataFrame(columns=[\"file\",\"population_size\", \"generations\", \"final_fitness\",  \"p_mutation\", \"p_crossover\", \"elite_percentage\", \"tournament_size\", \"max_depth\", \"mean_stats\", \"best_gen_stats\", \"stds\", \"std_last_gen\", \"grammar\"])\n",
    "else:\n",
    "    # If cache file exists, read it into a DataFrame\n",
    "    cache = pd.read_csv(cache_file)\n",
    "\n",
    "def convert_to_primitives(data):\n",
    "    \n",
    "    if isinstance(data, np.ndarray):\n",
    "        return data.tolist()\n",
    "    if isinstance(data, Dict):\n",
    "        print(type(data))\n",
    "        temp = {}\n",
    "        for k, v in data.items():\n",
    "            converted_k = convert_to_primitives(k)\n",
    "            converted_v = convert_to_primitives(v)\n",
    "            temp[converted_k] = converted_v\n",
    "        return temp\n",
    "    if isinstance(data, List):\n",
    "        temp = []\n",
    "        for item in data:\n",
    "            converted_item = convert_to_primitives(item)\n",
    "            temp.append(converted_item)\n",
    "        return temp\n",
    "    return data\n",
    "    \n",
    "def serialize_data(data):\n",
    "    # check if np array\n",
    "    temp = convert_to_primitives(data)\n",
    "    \n",
    "    return json.dumps(temp)\n",
    "\n",
    "def load_cache(cache_df, file, run_parameters):\n",
    "    mutation_rate = run_parameters['p_mutation']\n",
    "    crossover_rate = run_parameters['p_crossover']\n",
    "    elite_percentage = run_parameters['elite_percentage']\n",
    "    tournament_size = run_parameters['tournament_size']\n",
    "    population_size = run_parameters['population_size']\n",
    "    generations = run_parameters['generations']\n",
    "    max_depth = run_parameters['max_depth']\n",
    "    # Filter DataFrame based on conditions\n",
    "    cache_result = cache_df.query(f'file == \"{file}\" and population_size == {population_size} and generations == {generations} and p_mutation == {mutation_rate} and p_crossover == {crossover_rate} and elite_percentage == {elite_percentage} and tournament_size == {tournament_size} and max_depth == {max_depth}')\n",
    "    \n",
    "    # Check if there's a match\n",
    "    if not cache_result.empty:\n",
    "        # Extract the first match\n",
    "        result = cache_result.iloc[0]\n",
    "        mean_stats = json.loads(result['mean_stats'])\n",
    "        best_gen_stats = json.loads(result['best_gen_stats'])\n",
    "        stds = np.array(json.loads(result['stds']))\n",
    "        grammar = json.loads(result['grammar'])\n",
    "        print(\"Loaded from cache\")\n",
    "        display(cache_result)\n",
    "   \n",
    "        return mean_stats, best_gen_stats, stds, grammar\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_cache(cache_df, data, final_fitness, file, run_parameters):\n",
    "    mutation_rate = run_parameters['p_mutation']\n",
    "    crossover_rate = run_parameters['p_crossover']\n",
    "    elite_percentage = run_parameters['elite_percentage']\n",
    "    tournament_size = run_parameters['tournament_size']\n",
    "    population_size = run_parameters['population_size']\n",
    "    generation_count = run_parameters['generations']\n",
    "    max_depth = run_parameters['max_depth']\n",
    "    \n",
    "    mean_stats, best_gen_stats, _, stds, grammar = data\n",
    "    std_last_gen = serialize_data(stds[-1])\n",
    "    # Convert lists of lists into JSON\n",
    "    mean_stats_json = serialize_data(mean_stats)\n",
    "    best_gen_stats_json = serialize_data(best_gen_stats)\n",
    "    stds_json = serialize_data(stds)\n",
    "    grammar_json = serialize_data(grammar)\n",
    "\n",
    "    new_row = {\n",
    "        \"file\": file,\n",
    "        \"population_size\": population_size,\n",
    "        \"generations\": generation_count,\n",
    "        \"final_fitness\": final_fitness,\n",
    "        \"p_mutation\": mutation_rate,\n",
    "        \"p_crossover\": crossover_rate,\n",
    "        \"elite_percentage\": elite_percentage,\n",
    "        \"max_depth\": max_depth,\n",
    "        \"tournament_size\": tournament_size,\n",
    "        \"mean_stats\": mean_stats_json,\n",
    "        \"best_gen_stats\": best_gen_stats_json,\n",
    "        \"stds\": stds_json,\n",
    "        \"std_last_gen\": std_last_gen,\n",
    "        \"grammar\": grammar_json\n",
    "    }\n",
    "   \n",
    "    cache_df = pd.concat([cache_df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    cache_df.to_csv(cache_file, index=False)\n",
    "    return cache_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:32:24.019768Z",
     "start_time": "2023-05-16T10:31:20.309299Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_mutation()\n",
    "\n",
    "#test_fitness()\n",
    "#test_crossover()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-16T10:21:05.651662Z",
     "start_time": "2023-05-16T10:19:39.660424Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def mutate_genotype(parent_genotype, grammar, probability, empty_genotype ):\n",
    "    parameter_hash = genotype_hash(parent_genotype)\n",
    "    parameter_string = \"\"\n",
    "    sorted_keys = parent_genotype.keys()\n",
    "\n",
    "    # Create a string representation of the genotype\n",
    "    genotype_str = \"\"\n",
    "    for key in sorted_keys:\n",
    "        genotype_str += key + \":\"\n",
    "        # genotype_str += \",\".join(str(val) for val in genotype_param[key])\n",
    "        for i in range(len(parent_genotype[key])):\n",
    "            genotype_str += \",\" + str(parent_genotype[key][i])\n",
    "        genotype_str += \";\"\n",
    "\n",
    "    offspring_genotype = deep_copy_genotype(parent_genotype, empty_genotype.copy())\n",
    "\n",
    "    #parent_genotype[\"<expr\"] =  parent_genotype[\"<start>\"]\n",
    "    offspring_genotype_hash = genotype_hash(offspring_genotype)\n",
    "\n",
    "    #print(f\"pre mutation: Parent hash: {parameter_hash} To be mutated hash: {offspring_genotype_hash}\")\n",
    "\n",
    "    #print(\"Offspring genotype: \", offspring_genotype)\n",
    "    mutate_genotype_inplace(offspring_genotype, grammar, probability)\n",
    "\n",
    "    offspring_genotype_hash = genotype_hash(offspring_genotype)\n",
    "    parameter_hash_2 = genotype_hash(parent_genotype)\n",
    "\n",
    "    #print(f\"post mutation: Parent hash: {parameter_hash_2} Mutated hash: {offspring_genotype_hash}\")\n",
    "    try:\n",
    "        assert_equality_of_hashes(parameter_hash, parameter_hash_2)\n",
    "    except Exception as e:\n",
    "        print(\"Hash not equal after mutation, some race condition occured\")\n",
    "        #print(\"Parent genotype: \", parent_genotype)\n",
    "        #print(\"Pararent original genotype \", genotype_str)\n",
    "        #print(\"Offspring genotype: \", offspring_genotype)\n",
    "    #print(\"Parent genotype: \", parent_genotype)\n",
    "   # raise Exception(\"Stop\")\n",
    "    return offspring_genotype\n",
    "\n",
    "index_to_variable_name = {\n",
    "    0: \"best_fitness\",\n",
    "    1: \"worst_fitness\",\n",
    "    2: \"avg_fitness\",\n",
    "    3: \"better_than_father\",\n",
    "    4: \"worse_than_father\",\n",
    "    5: \"num_repeated\",\n",
    "    6: \"best_elite\",\n",
    "    7: \"worst_elite\",\n",
    "    8: \"avg_elite\",\n",
    "    9: \"num_elite\",\n",
    "    10: \"survivors\"\n",
    "}\n",
    "\n",
    "\n",
    "def parse_df(case_df):\n",
    "    # y is the last column from the df, extract it to y\n",
    "    y = case_df.iloc[:, -1].to_numpy()\n",
    "\n",
    "    # drop the last column from the df, and store the rest in X\n",
    "    X = case_df.drop(case_df.columns[-1], axis=1)\n",
    "    variable_matrix = X.to_numpy()\n",
    "\n",
    "    return variable_matrix, y\n",
    "\n",
    "@njit\n",
    "def median_absolute_deviation(data):\n",
    "    median = np.median(data)\n",
    "    deviations = np.abs(data - median)\n",
    "    mad = np.median(deviations)\n",
    "    return mad\n",
    "\n",
    "test_file = \"synth1/synth1-test.csv\"\n",
    "\n",
    "def selection_lexicase_wrapper(gnotype_list, grammar, NODE_TYPE, GENOTYPE_TYPE, tournament_size=2):\n",
    "    df_test = pd.read_csv(test_file, header=None)\n",
    "    variable_values_test, y_values_test = parse_df(df_test)\n",
    "    expected_selection = np.ceil(len(gnotype_list) / tournament_size)\n",
    "    solutions = set()\n",
    "    iterations_with_no_change = 0\n",
    "    last_length = 0\n",
    "    while (len(solutions) < expected_selection):\n",
    "        current_candiates = selection_epsilon_lexicase(gnotype_list, variable_values_test, y_values_test, grammar, NODE_TYPE, GENOTYPE_TYPE)\n",
    "        for candidate in current_candiates:\n",
    "            solutions.add(candidate)\n",
    "        # garantia de parada se as soluções não mudarem\n",
    "        if len(solutions) == last_length:\n",
    "            iterations_with_no_change += 1\n",
    "        else:\n",
    "            iterations_with_no_change = 0\n",
    "            last_length = len(solutions)\n",
    "\n",
    "        #print(f\"Current {len(solutions)} elements selected.\")\n",
    "        #print(solutions)\n",
    "\n",
    "        if iterations_with_no_change > expected_selection:\n",
    "            #print(\"No change for too long, breaking\")\n",
    "            break\n",
    "    return solutions\n",
    "@njit\n",
    "def get_random_indices(num_cases):\n",
    "    # Generate a list of indices\n",
    "    indices = np.arange(num_cases)\n",
    "\n",
    "    # Create a copy of indices for shuffling\n",
    "    shuffled_indices = indices.copy()\n",
    "\n",
    "    # Perform Fisher-Yates shuffle\n",
    "    for i in range(num_cases):\n",
    "        # Get a random index\n",
    "        j = np.random.randint(i, num_cases)\n",
    "\n",
    "        # Swap i-th and j-th elements\n",
    "        shuffled_indices[i], shuffled_indices[j] = shuffled_indices[j], shuffled_indices[i]\n",
    "\n",
    "    return shuffled_indices\n",
    "\n",
    "@njit\n",
    "def selection_epsilon_lexicase(genotype_list, variables_values_test, y_values_test, grammar, NODE_TYPE, GENOTYPE_TYPE, epsilon=None, maximize=False):\n",
    "    num_individuals = len(genotype_list)\n",
    "\n",
    "    # possible test cases\n",
    "    num_cases = len(y_values_test)\n",
    "\n",
    "    candidates = list(range(num_individuals))\n",
    "\n",
    "    case_indices = get_random_indices(num_cases)\n",
    "    last_index = 0\n",
    "\n",
    "    # more than one candidate and there are cases left to evaluate\n",
    "    while len(candidates) > 1 and last_index < num_cases:\n",
    "\n",
    "        current_case_index = case_indices[last_index]\n",
    "        last_index += 1\n",
    "\n",
    "        # Evaluate the fitness of the remaining candidates for the current case\n",
    "\n",
    "        # create empty list of genotypes\n",
    "        candidate_list = [GENOTYPE_TYPE.copy() for _ in range(len(candidates))]\n",
    "\n",
    "        for i in range(len(candidates)):\n",
    "            candidate = candidates[i]\n",
    "            #copied_genotype = deep_copy_genotype(genotype_list[candidate], GENOTYPE_TYPE.copy())\n",
    "            copied_genotype = genotype_list[candidate]\n",
    "            candidate_list[i] = copied_genotype\n",
    "\n",
    "        current_variable_values = [variables_values_test[current_case_index]]\n",
    "        current_y = [y_values_test[current_case_index]]\n",
    "\n",
    "            #candidate_fitness, _ = calculate_fitness(current_variable_values, current_y,copied_genotype, grammar, NODE_TYPE, GENOTYPE_TYPE)\n",
    "        current_case_fitness = calculate_all_fitnesses(candidate_list, current_variable_values, current_y, grammar, NODE_TYPE, GENOTYPE_TYPE )\n",
    "\n",
    "        best_fitness = min(current_case_fitness) if not maximize else max(current_case_fitness)\n",
    "\n",
    "        if epsilon is None:\n",
    "            epsilon = median_absolute_deviation(current_case_fitness)\n",
    "\n",
    "        # Remove candidates with fitness worse than the best for the current case\n",
    "        candidates = [candidate for idx, candidate in enumerate(candidates) if current_case_fitness[idx] <= best_fitness + epsilon]\n",
    "\n",
    "        #for idx, candidate in enumerate(candidates):\n",
    "        #    if current_case_fitness[idx] <= best_fitness + epsilon:\n",
    "        #        candidates.append(candidate)\n",
    "    #if len(candidates) > 1:\n",
    "    #    picked_index = random_int(0, len(candidates) - 1)\n",
    "    #    return candidates[picked_index]\n",
    "    #else:\n",
    "    #    return candidates[0]\n",
    "    return candidates\n",
    "\n",
    "def next_generation(genotype_list,\n",
    "                    grammar: dict,\n",
    "                    p_mutation: float,\n",
    "                    p_crossover: float,\n",
    "                    elite_percentage: float,\n",
    "                    variables_values: np.ndarray,\n",
    "                    y_values: np.ndarray,\n",
    "                    tournament_size: int,\n",
    "                    print_run_logs=False):\n",
    "\n",
    "    population_size = len(genotype_list)\n",
    "\n",
    "    def calculate_single_fitness(genotype):\n",
    "        rmse, _ = calculate_fitness(variables_values, y_values, genotype, grammar, NODE_TYPE, GENOTYPE_TYPE)\n",
    "        return rmse\n",
    "\n",
    "    # Calculate fitness for all genotypes\n",
    "    fitness_list = calculate_all_fitnesses(genotype_list, variables_values, y_values, grammar, NODE_TYPE, GENOTYPE_TYPE)\n",
    "\n",
    "    # print(\"After fitness genotypes: \")\n",
    "    #\n",
    "    # for i in range(len(genotype_list)):\n",
    "    #     print(\"\\nGenotype: \", i)\n",
    "    #     print_resumed_genotype(genotype_list[i])\n",
    "    # print(\"\\n\\n\\n\")\n",
    "\n",
    "    unique, counts = np.unique(fitness_list, return_counts=True)\n",
    "\n",
    "\n",
    "\n",
    "    # Count number of repeated items\n",
    "    num_repeated = np.sum(counts) - len(counts)\n",
    "\n",
    "    # Metrics: Best and worst fitness\n",
    "    best_fitness = np.min(fitness_list)\n",
    "    worst_fitness = np.max(fitness_list)\n",
    "\n",
    "    # Metrics: Average fitness\n",
    "    avg_fitness = np.mean(fitness_list)\n",
    "\n",
    "\n",
    "    # Select the elite individuals\n",
    "    num_elite = int(population_size * elite_percentage)\n",
    "    elite_indices = best_n_items(fitness_list, num_elite)\n",
    "    elite_genotypes = [genotype_list[idx] for idx in elite_indices]\n",
    "\n",
    "    elite_fitness = [fitness_list[idx] for idx in elite_indices]\n",
    "\n",
    "    best_elite = np.min(elite_fitness)\n",
    "    worst_elite = np.max(elite_fitness)\n",
    "    avg_elite = np.mean(elite_fitness)\n",
    "\n",
    "    # Tournament selection for survivors\n",
    "    survivors_indices = selection_lexicase_wrapper(genotype_list, grammar, NODE_TYPE, GENOTYPE_TYPE)\n",
    "    \n",
    "    #survivors_indices = selection_tournament(fitness_list, tournament_size)\n",
    "\n",
    "    survivor_hashes = [genotype_hash(genotype_list[idx]) for idx in survivors_indices]\n",
    "\n",
    "    survivors_genotypes = [genotype_list[idx] for idx in survivors_indices]\n",
    "\n",
    "\n",
    "    worse_than_father = 0\n",
    "    better_than_father = 0\n",
    "\n",
    "    survivors = len(survivors_genotypes)\n",
    "\n",
    "    # Reproduce, mutate, and crossover to create new offspring\n",
    "    new_genotypes = []\n",
    "    while len(new_genotypes) < population_size - num_elite:\n",
    "        if print_run_logs:\n",
    "            print(\"\\n\\nPopulation size: \", len(new_genotypes))\n",
    "        r = np.random.random()\n",
    "        parent_idx = np.random.randint(0, len(survivors_genotypes))\n",
    "        parent_genotype = survivors_genotypes[parent_idx]\n",
    "        #print_resumed_genotype(parent_genotype)\n",
    "        if print_run_logs:\n",
    "            print(f\"Hash for parent: {survivor_hashes[parent_idx]}\")\n",
    "\n",
    "        if r < p_mutation:\n",
    "            if print_run_logs:\n",
    "                print(\"Mutating...\")\n",
    "            # Mutate\n",
    "            offspring_genotype = mutate_genotype(parent_genotype, grammar, p_mutation, GENOTYPE_TYPE)\n",
    "        elif r < p_mutation + p_crossover:\n",
    "            if print_run_logs:\n",
    "                print(\"Crossover...\")\n",
    "            # Crossover\n",
    "            parent2_idx = np.random.randint(0, len(survivors_genotypes))\n",
    "\n",
    "            attemps = 0\n",
    "            max_attemps = 10\n",
    "            while parent2_idx == parent_idx and attemps < max_attemps:\n",
    "                parent2_idx = np.random.randint(0, len(survivors_genotypes))\n",
    "                attemps += 1\n",
    "            if attemps == max_attemps:\n",
    "                if print_run_logs:\n",
    "                    print(\"Couldn't find a different parent to crossover, doing parthenogenesis\")\n",
    "                # If we couldn't find a different parent, just mutate\n",
    "                parent2_idx = parent_idx\n",
    "\n",
    "            if print_run_logs:\n",
    "                print(f\"Hash for parent 2: {survivor_hashes[parent2_idx]}\")\n",
    "\n",
    "            parent2_genotype = survivors_genotypes[parent2_idx]\n",
    "            #print_resumed_genotype(parent_genotype)\n",
    "            #print_resumed_genotype(parent2_genotype)\n",
    "            # print(\"++++++++++ end parents\")\n",
    "            offspring_1, offspring_2 = crossover_numba(parent_genotype, parent2_genotype, p_crossover, GENOTYPE_TYPE)\n",
    "\n",
    "            #print_resumed_genotype(offspring_1)\n",
    "            #print_resumed_genotype(offspring_2)\n",
    "\n",
    "            parents_mean_fitness = (fitness_list[parent_idx] + fitness_list[parent2_idx]) / 2\n",
    "\n",
    "            offspring_1_fitness = calculate_single_fitness(offspring_1)\n",
    "            offspring_2_fitness = calculate_single_fitness(offspring_2)\n",
    "            if print_run_logs:\n",
    "                print(\"Created offspring with fitness: \", offspring_1_fitness, \" and \", offspring_2_fitness)\n",
    "            if offspring_1_fitness < parents_mean_fitness:\n",
    "                better_than_father += 1\n",
    "            else:\n",
    "                worse_than_father += 1\n",
    "            if offspring_2_fitness < parents_mean_fitness:\n",
    "                better_than_father += 1\n",
    "            else:\n",
    "                worse_than_father += 1\n",
    "\n",
    "            offspring_genotype = offspring_1\n",
    "            new_genotypes.append(offspring_2)\n",
    "        else:\n",
    "            if print_run_logs:\n",
    "                print(\"Reproducing...\")\n",
    "            # Reproduce\n",
    "            offspring_genotype = deep_copy_genotype(parent_genotype, GENOTYPE_TYPE.copy())\n",
    "\n",
    "        new_genotypes.append(offspring_genotype)\n",
    "\n",
    "    # Combine elite and new offspring to create the next generation\n",
    "    next_gen = elite_genotypes + new_genotypes\n",
    "\n",
    "    # take the extra genotypes out\n",
    "    if len(next_gen) > population_size:\n",
    "        fitness_list_next_gen = calculate_all_fitnesses(next_gen, variables_values, y_values, grammar, NODE_TYPE, GENOTYPE_TYPE)\n",
    "        worst_individuals = selection_tournament(fitness_list_next_gen, len(fitness_list_next_gen), True)\n",
    "        if print_run_logs:\n",
    "            print(\"Worst individuals for removal: \", worst_individuals)\n",
    "        for idx in worst_individuals:\n",
    "            del next_gen[idx]\n",
    "\n",
    "\n",
    "\n",
    "    variables = np.array([\n",
    "        best_fitness,\n",
    "        worst_fitness,\n",
    "        avg_fitness,\n",
    "        better_than_father,\n",
    "        worse_than_father,\n",
    "        num_repeated,\n",
    "        best_elite,\n",
    "        worst_elite,\n",
    "        avg_elite,\n",
    "        num_elite,\n",
    "        survivors\n",
    "    ])\n",
    "    if print_run_logs:\n",
    "        for i, value in enumerate(variables):\n",
    "            print(f\"{index_to_variable_name[i]}: {value}\")\n",
    "\n",
    "        print(\"Next gen length: \", len(next_gen))\n",
    "\n",
    "    return next_gen, variables\n",
    "\n",
    "\n",
    "genotypes, grammar = create_n_genotypes(20, 3, 2)\n",
    "\n",
    "# print(\"Original genotypes: \")\n",
    "# for i in range(len(genotypes)):\n",
    "#     print(\"\\nGenotype: \", i)\n",
    "#     print_resumed_genotype(genotypes[i])\n",
    "# print(\"\\n\\n\\n\")\n",
    "\n",
    "test_data = np.array([[-1.23592861, -1.36410559],\n",
    "                      [-0.60259712, -0.60758157],\n",
    "                      [2.80419539, 2.66919459],\n",
    "                      [-0.22628393, -2.97797806],\n",
    "                      [2.0402239, -0.59282888]])\n",
    "\n",
    "test_y = np.array([6.51571868, 1.14283484, 40.67709954, 7.42636336, 9.6026114])\n",
    "\n",
    "next_gen, stats_from_run = next_generation(genotypes, grammar, 0.3, 0.6, 0.1, test_data, test_y, 2, True)\n",
    "\n",
    "print(\"\\n\\nReturned stat values: \")\n",
    "for i, var in enumerate(stats_from_run):\n",
    "    print(f\"{index_to_variable_name[i]}: {var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T21:47:21.681020Z",
     "start_time": "2023-05-14T21:46:55.021506Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def genetic_programming(num_generations, population_size, max_depth, p_mutation, p_crossover, elite_percentage, variables_values, y_values, tournament_size, silent_run=False):\n",
    "\n",
    "    num_variables = len(variables_values[0])\n",
    "    #print(\"Number of variables: \", num_variables)\n",
    "\n",
    "    # Create the grammar\n",
    "    genotype_list, grammar = create_n_genotypes(population_size, max_depth, num_variables)\n",
    "    used_grammar = grammar\n",
    "    # Initialize the genotypes\n",
    "    current_genotypes = genotype_list\n",
    "\n",
    "    # Define the statistics array to store the statistics for each generation\n",
    "    stats_columns = len(index_to_variable_name)\n",
    "\n",
    "    stats_shape = (num_generations, stats_columns)\n",
    "    stats = np.zeros(shape=stats_shape, dtype=np.float64)\n",
    "\n",
    "    iterator_wrapper = tqdm(range(num_generations), desc=\"Generations\") if not silent_run else range(num_generations)\n",
    "\n",
    "    # Run the algorithm for the specified number of generations\n",
    "    for generation in iterator_wrapper:\n",
    "        if not silent_run:\n",
    "            print(f\"\\n=== Generation {generation + 1} ===\")\n",
    "        current_genotypes, current_stats = next_generation(current_genotypes, grammar, p_mutation, p_crossover, elite_percentage, variables_values, y_values, tournament_size, False)\n",
    "\n",
    "        # Store the statistics for the current generation\n",
    "        stats[generation, :] = current_stats\n",
    "\n",
    "    return stats, current_genotypes, grammar\n",
    "\n",
    "# read csv from inside synth1, called synth1-train.csv\n",
    "\n",
    "df = pd.read_csv(\"synth1/synth1-train.csv\", header=None)\n",
    "display(df.head())\n",
    "\n",
    "variable_matrix, y = parse_df(df)\n",
    "\n",
    "\n",
    "stats, final_genotypes, used_grammar = genetic_programming(200, 50, 5, 0.2, 0.7, 0.1, variable_matrix, y, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T21:47:26.359057Z",
     "start_time": "2023-05-14T21:47:21.647350Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def plot_stats(stats, index_to_variable_name, title=\"\"):\n",
    "    num_generations, num_stats = stats.shape\n",
    "\n",
    "    num_cols = 4\n",
    "    num_rows = math.ceil(num_stats / num_cols)\n",
    "\n",
    "    # Create a subplot for each statistic in a mosaic grid\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 6 * num_rows), sharex=True)\n",
    "    axs = axs.flatten()  # Flatten the array to make it easier to work with\n",
    "\n",
    "    # Plot the statistics on the corresponding subplot\n",
    "    for i in range(num_stats):\n",
    "        axs[i].plot(range(1, num_generations + 1), stats[:, i], label=index_to_variable_name[i])\n",
    "        axs[i].set_title(index_to_variable_name[i])\n",
    "        axs[i].set_xlabel(f\"{num_generations} generations\")\n",
    "        axs[i].set_ylabel(\"Value\")\n",
    "        axs[i].legend()\n",
    "\n",
    "    # If there are empty subplots, make them invisible\n",
    "    for i in range(num_stats, len(axs)):\n",
    "        axs[i].axis(\"off\")\n",
    "\n",
    "    # Adjust the layout of the subplots\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if title == \"\":\n",
    "        title = f\"Run statistics for {num_generations} generations\"\n",
    "    fig.suptitle(title, fontsize=20, y=1.02)\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "run_parameters = {\n",
    "    \"generations\": 200,\n",
    "    \"population_size\": 25,\n",
    "    \"max_depth\": 5,\n",
    "    \"p_mutation\": 0.2,\n",
    "    \"p_crossover\": 0.7,\n",
    "    \"elite_percentage\": 0.1,\n",
    "    \"tournament_size\": 2\n",
    "}\n",
    "data_save = (stats, stats, final_genotypes[0],stats[-1], used_grammar )\n",
    "#cache = save_cache(cache, data_save, stats[0], \"test\", run_parameters)\n",
    "\n",
    "plot_stats(stats, index_to_variable_name)\n",
    "print(stats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a cada variação de semente\n",
    "\n",
    "Não uso mais mas deixei a função no código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T21:50:39.003173Z",
     "start_time": "2023-05-14T21:50:36.001415Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def run_and_plot_every_iteration(max_depth=3, p_mutation=0.05, p_crossover=0.09, elite_percentage=0.1, variables_values=variable_matrix, y_values=y, tournament_size=10):\n",
    "\n",
    "    stats_list = []\n",
    "    final_genotypes_list = []\n",
    "    final_used_grammar = None\n",
    "\n",
    "    generations = 40\n",
    "    population_size = 50\n",
    "    random_iterations = 30\n",
    "\n",
    "    best_fitness_experiment = 0\n",
    "    best_fitness_value = 10000000\n",
    "    base_seed = 0\n",
    "    for i in tqdm(range(random_iterations), desc=\"Random iterations\"):\n",
    "            base_seed += 1\n",
    "            seed(base_seed)\n",
    "            np.random.seed(base_seed)\n",
    "\n",
    "            stats, final_genotypes, used_grammar = genetic_programming(generations, population_size, max_depth, p_mutation, p_crossover, elite_percentage, variables_values, y_values, tournament_size)\n",
    "            stats_list.append(stats)\n",
    "            final_genotypes_list.append(final_genotypes)\n",
    "            final_used_grammar = used_grammar\n",
    "\n",
    "            # get the best fitness from the last generation\n",
    "            best_fitness_current = stats[-1, 0]\n",
    "            if best_fitness_current < best_fitness_value:\n",
    "                best_fitness_value = best_fitness_current\n",
    "                best_fitness_experiment = i\n",
    "            print(\"Case: \", i, \" best fitness: \", best_fitness_current)\n",
    "            plot_stats(stats, index_to_variable_name)\n",
    "\n",
    "    # get the run with the best fitness overall\n",
    "    best_genotypes = final_genotypes_list[best_fitness_experiment]\n",
    "\n",
    "\n",
    "    # get the best genotype from the final generation of the best experiment\n",
    "    fitness_list = calculate_all_fitnesses(best_genotypes, variable_matrix, y, grammar, NODE_TYPE, GENOTYPE_TYPE)\n",
    "\n",
    "    # get the index of the best genotype\n",
    "    best_index = best_n_items(fitness_list, 1)\n",
    "\n",
    "    best_genotype = final_genotypes[best_index[0]]\n",
    "\n",
    "    # print the best genotype\n",
    "    print(\"Final function: \")\n",
    "    copied_best = deep_copy_genotype(best_genotype, GENOTYPE_TYPE.copy())\n",
    "    create_full_tree_from_genome(copied_best, final_used_grammar, NODE_TYPE, True)\n",
    "\n",
    "    best_stats = stats_list[best_fitness_experiment]\n",
    "\n",
    "    plot_stats(best_stats, index_to_variable_name)\n",
    "#run_and_collect_data(3, 0.05, 0.9, 0.1, variable_matrix, y, 10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Método principal de testes\n",
    "\n",
    "Recebe um arquivo de treinamento, parâmetros de execução e uma semente base.\n",
    "Com isso, é capaz de inferir a quantidade de variáveis, criar a gramática de acordo, e instanciar n gerações do problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T22:49:27.264449Z",
     "start_time": "2023-05-14T22:40:47.218238Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def run_random_variations(train_filename, run_parameters, base_seed=0):\n",
    "    df_train = pd.read_csv(train_filename, header=None)\n",
    "\n",
    "    variable_matrix, y = parse_df(df_train)\n",
    "\n",
    "    stats_list = []\n",
    "    final_genotypes_list = []\n",
    "    final_used_grammar = None\n",
    "\n",
    "    print(f\"Experiments with  {run_parameters['generations']} generations and population size {run_parameters['population_size']}\")\n",
    "    random_iterations = 10\n",
    "\n",
    "    best_fitness_experiment = 0\n",
    "    best_fitness_value = 10000000\n",
    "    base_seed = base_seed\n",
    "    for i in tqdm(range(random_iterations), desc=\"Random iterations\"):\n",
    "        base_seed += 1\n",
    "        seed(base_seed)\n",
    "        np.random.seed(base_seed)\n",
    "\n",
    "        stats, final_genotypes, used_grammar = genetic_programming(run_parameters['generations'], run_parameters['population_size'], run_parameters[\"max_depth\"], run_parameters[\"p_mutation\"], run_parameters[\"p_crossover\"], run_parameters[\"elite_percentage\"], variable_matrix, y, run_parameters[\"tournament_size\"], True)\n",
    "        stats_list.append(stats)\n",
    "        final_genotypes_list.append(final_genotypes)\n",
    "        final_used_grammar = used_grammar\n",
    "\n",
    "        # get the best fitness from the last generation\n",
    "        best_fitness_current = stats[-1, 0]\n",
    "        if best_fitness_current < best_fitness_value:\n",
    "            best_fitness_value = best_fitness_current\n",
    "            best_fitness_experiment = i\n",
    "\n",
    "\n",
    "    mean_stats = np.mean(stats_list, axis=0)\n",
    "\n",
    "    stds_across_stats = np.std(stats_list, axis=0)\n",
    "\n",
    "    print(\"Stds of the problem across generations\")\n",
    "    for i in range(len(index_to_variable_name)):\n",
    "        print(f\"{index_to_variable_name[i]}: {stds_across_stats[-1, i]}\")\n",
    "\n",
    "\n",
    "    title = f\"Pop size {run_parameters['population_size']} and {run_parameters['generations']} generations. \\nPmut = {run_parameters['p_mutation']}\\n Pcross = {run_parameters['p_crossover']}\"\n",
    "    \n",
    "    plot_stats(mean_stats, index_to_variable_name, f\"Mean values for {random_iterations} runs - {title}\")\n",
    "    plot_stats(stats_list[best_fitness_experiment], index_to_variable_name, f\"Best fitness - {title}\")\n",
    "\n",
    "    return mean_stats, stats_list[best_fitness_experiment],  final_genotypes_list[best_fitness_experiment], stds_across_stats, final_used_grammar\n",
    "\n",
    "\n",
    "\n",
    "run_parameters = {\n",
    "    \"generations\": 20,\n",
    "    \"population_size\": 25,\n",
    "    \"max_depth\": 5,\n",
    "    \"p_mutation\": 0.3,\n",
    "    \"p_crossover\": 0.7,\n",
    "    \"elite_percentage\": 0.1,\n",
    "    \"tournament_size\": 2\n",
    "}\n",
    "\n",
    "agg, best_gen_stats, best_genotypes, stds, grammar = run_random_variations(\"synth1/synth1-train.csv\", run_parameters, 0)\n",
    "\n",
    "data_cache = (agg, best_gen_stats, best_genotypes, stds, grammar)\n",
    "final_fitness = best_gen_stats[-1, 0]\n",
    "cache = save_cache(cache, data_cache, final_fitness, \"synth1/synth1-train.csv\", run_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"synth1/synth1-train.csv\", \"synth2/synth2-train.csv\", \"concrete/concrete-train.csv\"]\n",
    "test_files = [\"synth1/synth1-test.csv\", \"synth2/synth2-test.csv\", \"concrete/concrete-test.csv\"]\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    test_file = test_files[i]\n",
    " # variate mutation rate by 0.05, until 0.9\n",
    "    for p_mut in range(5, 100, 5):\n",
    "        \n",
    "        mutation_rate = p_mut / 100\n",
    "        crossover_rate = 1 - mutation_rate\n",
    "        run_parameters = {\n",
    "            \"generations\": 70,\n",
    "            \"population_size\": 100,\n",
    "            \"max_depth\": 5,\n",
    "            \"p_mutation\": mutation_rate,\n",
    "            \"p_crossover\": crossover_rate,\n",
    "            \"elite_percentage\": 0.1,\n",
    "            \"tournament_size\": 2\n",
    "        }\n",
    "        print(\"NEW PARAMETERS________________\")\n",
    "        print(f\"pmut = {run_parameters['p_mutation']}, pcross = {run_parameters['p_crossover']}, elite = {run_parameters['elite_percentage']}\")\n",
    "\n",
    "        returned_data = load_cache(cache, file, run_parameters)\n",
    "        if returned_data is not None:\n",
    "            print(\"Found in cache! Skipping...\")\n",
    "            mean_stats, best_gen_stats, stds, grammar  = returned_data\n",
    "        else:\n",
    "            mean_stats, best_gen_stats, best_genotypes, stds, grammar  = run_random_variations(file, run_parameters, 0)\n",
    "            data_to_cache = (mean_stats, best_gen_stats, best_genotypes, stds, grammar)\n",
    "            final_fitness = best_gen_stats[-1, 0]\n",
    "            print(\"Saving to cache!\")\n",
    "            cache = save_cache(cache, data_cache, final_fitness, \"synth1/synth1-train.csv\", run_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variate mutation rate by 0.05, until 0.9\n",
    "test_file = \"synth2/synth2-test.csv\"\n",
    "\n",
    "# for p_mut in range(5, 100, 5):\n",
    "#     mutation_rate = p_mut / 100\n",
    "#     crossover_rate = 1 - mutation_rate\n",
    "#     run_parameters = {\n",
    "#         \"generations\": 150,\n",
    "#         \"population_size\": 100,\n",
    "#         \"max_depth\": 5,\n",
    "#         \"p_mutation\": mutation_rate,\n",
    "#         \"p_crossover\": crossover_rate,\n",
    "#         \"elite_percentage\": 0.1,\n",
    "#         \"tournament_size\": 2\n",
    "#     }\n",
    "#     print(\"NEW PARAMETERS________________\")\n",
    "#     print(f\"pmut = {run_parameters['p_mutation']}, pcross = {run_parameters['p_crossover']}, elite = {run_parameters['elite_percentage']}\")\n",
    "#     agg, best_gen_stats, best_genotypes, stds, grammar = run_random_variations(\"synth2/synth2-train.csv\", run_parameters, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variate mutation rate by 0.05, until 0.9\n",
    "test_file = \"concrete/concrete-test.csv\"\n",
    "# for p_mut in range(5, 100, 5):\n",
    "#     mutation_rate = p_mut / 100\n",
    "#     crossover_rate = 1 - mutation_rate\n",
    "#     run_parameters = {\n",
    "#         \"generations\": 150,\n",
    "#         \"population_size\": 100,\n",
    "#         \"max_depth\": 5,\n",
    "#         \"p_mutation\": mutation_rate,\n",
    "#         \"p_crossover\": crossover_rate,\n",
    "#         \"elite_percentage\": 0.1,\n",
    "#         \"tournament_size\": 2\n",
    "#     }\n",
    "#     print(\"NEW PARAMETERS________________\")\n",
    "#     print(f\"pmut = {run_parameters['p_mutation']}, pcross = {run_parameters['p_crossover']}, elite = {run_parameters['elite_percentage']}\")\n",
    "#     agg, best_gen_stats, best_genotypes, stds, grammar = run_random_variations(\"concrete/concrete-train.csv\", run_parameters, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T21:50:35.859972Z",
     "start_time": "2023-05-14T21:50:16.546094Z"
    },
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_test_fitness_per_genome(genotype_list, grammar, test_filename=\"synth1/synth1-train.csv\"):\n",
    "    df_test = pd.read_csv(test_filename, header=None)\n",
    "\n",
    "    variable_matrix, y = parse_df(df_test)\n",
    "    fitness_list = calculate_all_fitnesses(genotype_list, variable_matrix, y, grammar, NODE_TYPE, GENOTYPE_TYPE)\n",
    "\n",
    "    print(\"Genotypes: \", len(genotype_list))\n",
    "    for i, g in enumerate(genotypes):\n",
    "        print(f\"For the {i}th genotype, function is\", sep=\" \")\n",
    "        copied_g = deep_copy_genotype(g, GENOTYPE_TYPE.copy())\n",
    "        create_full_tree_from_genome(copied_g, grammar, NODE_TYPE, True)\n",
    "    print(fitness_list)\n",
    "    x_values = range(len(fitness_list))\n",
    "    y_values = np.array(fitness_list)\n",
    "    mean_value = np.mean(y_values)\n",
    "\n",
    "    plt.bar(x_values, y_values, color='skyblue', edgecolor='black')\n",
    "    plt.axhline(y=mean_value, color='red', linestyle='--', label='Mean')\n",
    "\n",
    "    plt.xlabel('Genotype Index')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.title('Comparison with test case')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.grid(axis='y', linestyle='--')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "copy_best_genotypes = best_genotypes\n",
    "plot_test_fitness_per_genome(copy_best_genotypes, grammar, \"synth2/synth2-test.csv\")\n",
    "\n",
    "# Esse método funcionava bem, mas como refatorei para usar a lexicase, o genotipo que ele utilizava nao funciona mais e quebra..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
